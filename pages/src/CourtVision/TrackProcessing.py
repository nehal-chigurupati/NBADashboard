# -*- coding: utf-8 -*-
"""TrackProcessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZdjZCGC3pz7eRY5BhQjVtWyrTOliZxDS
"""

import pandas as pd
import numpy as np
import jsonlines
import json
import cv2
import os
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy.signal import savgol_filter
from scipy.stats import mode
from sklearn.cluster import KMeans
import joblib
import streamlit as st


nba_team_abbreviations = [
    'ATL', 'BOS', 'BKN', 'CHA', 'CHI', 'CLE', 'DAL', 'DEN',
    'DET', 'GSW', 'HOU', 'IND', 'LAC', 'LAL', 'MEM', 'MIA',
    'MIL', 'MIN', 'NOP', 'NYK', 'OKC', 'ORL', 'PHI', 'PHX',
    'POR', 'SAC', 'SAS', 'TOR', 'UTA', 'WAS'
]

def compute_center(x1, y1, x2, y2):
  return (x1 + x2) / 2, (y1 + y2) / 2

def get_rgb_data(json_out):
  rgb_dict = []
  track_nums = []
  center_x = []
  center_y = []
  frame_num = []

  for item in json_out.keys():
    if item != "META":
      for i in range(len(json_out[item]["R"])):
        R = json_out[item]["R"][i]
        G = json_out[item]["G"][i]
        B = json_out[item]["B"][i]

        rgb_dict.append([R, G, B])

        track_nums.append(item)
        c_x, c_y = compute_center(
                      json_out[item]["X1"][i],
                      json_out[item]["Y1"][i],
                      json_out[item]["X2"][i],
                      json_out[item]["Y2"][i]
                    )
        center_x.append(c_x)
        center_y.append(c_y)
        frame_num.append(i)

  return rgb_dict, track_nums, center_x, center_y, frame_num

def cluster_rgb_data(data, n_clusters):
  colors = np.array(data)
  kmeans = KMeans(n_clusters=n_clusters)
  clusters = kmeans.fit_predict(colors)

  return clusters, kmeans

def visualize_clusters(data, clusters, n_clusters):
  colors = np.array(data)

  plt.figure(figsize=(10, 6))

  for cluster_num in range(n_clusters):
      cluster_points = colors[clusters == cluster_num]
      plt.scatter(
          np.full_like(cluster_points[:, 0], cluster_num),  # X-axis (cluster number)
          cluster_points[:, 1],  # Y-axis (arbitrarily ordered)
          c=cluster_points / 255.0,  # Color based on RGB values
          marker='o',
          label=f'Cluster {cluster_num + 1}'
      )

  plt.title('Scatter Plot of RGB Colors by Cluster')
  plt.xlabel('Cluster Number')
  plt.ylabel('Arbitrarily Ordered Y-axis')
  plt.legend()
  plt.show()

@st.cache_data
def process_colors(json_out, n_clusters):
  rgb_data, track_nums, center_x, center_y, frame_num = get_rgb_data(json_out)
  clusters, model = cluster_rgb_data(rgb_data, n_clusters)

  #visualize_clusters(rgb_data, clusters, n_clusters)
  rgb_output_data = pd.DataFrame(np.array(rgb_data), columns=["R", "G", "B"])
  rgb_output_data["CLUSTER"] = clusters
  rgb_output_data["TRACK_NUM"] = track_nums
  rgb_output_data["X"] = center_x
  rgb_output_data["Y"] = center_y
  rgb_output_data["FRAME_NUM"] = frame_num

  return rgb_output_data, model.cluster_centers_, model

def get_color_labels(color1, color2):
    st.subheader("Associate jersey colors with teams")
    colors = np.array([color1, color2]) / 255.0  # Normalize RGB values to [0, 1]
    plt.imshow([colors])
    plt.axis('off')
    st.pyplot(plt)


    label1 = "not_inputted"
    label2 = "not_inputted"
    #get user input for color labels
    label1 = st.selectbox(label="Enter a label for the left color: ", options=nba_team_abbreviations, index=None)

    label2 = "not_inputted"
    if label1 and label2 != "not_inputted":
      label2 = st.selectbox(label="Enter a label for the right color: ", options=[i for i in nba_team_abbreviations if i != label1], index=None)

    if label1 != "not_inputted" and label2 != "not_inputted":
      return label1, label2



def associate_team_with_cluster(data, centers):
  team_one, team_two = get_color_labels(centers[0], centers[1])
  if team_one and team_two:
    team_df = pd.DataFrame({"TEAM_ABBREV": [team_one, team_two], "CLUSTER": [0, 1]})

    out_df = data.merge(team_df, on="CLUSTER")

    return out_df
  else:
    return None

def get_track_teams(json_out, title="", save_kmeans_model=False):
  data, centers, model = process_colors(json_out, 2)
  out_team = associate_team_with_cluster(data, centers)

  if save_kmeans_model:
    joblib.dump(model, "kmeans_model_" + title + ".pkl")
  
  if out_team != None:
    out = associate_track_with_team(out_team)
    return out
  else:
    return None



def associate_track_with_team(df):
  df['MODE_TEAM_ABBREV'] = df.groupby('TRACK_NUM')['TEAM_ABBREV'].transform(lambda x: x.mode().iloc[0])
  return df

def get_val_counts(list):
  data = pd.Series(list).value_counts()
  vals = []
  counts = []
  for index, value in data.items():
    vals.append(index)
    counts.append(value)

  return pd.DataFrame({"NUM": vals, "COUNT": counts})

#Use a Savitzky-Golay filter to smooth out trajectories
def savitzky_golay(x, y, t, window_size=3, poly_order=2):
  smooth_x = savgol_filter(x, window_size, poly_order)
  smooth_y = savgol_filter(y, window_size, poly_order)


  plt.plot(t, x, 'o', label='Original x')
  plt.plot(t, y, 'o', label='Original y')
  plt.plot(t, smooth_x, label='Smoothed x')
  plt.plot(t, smooth_y, label='Smoothed y')
  plt.legend()
  plt.show()

  return smooth_x, smooth_y

def get_track_frame_length(track_data):
  return len(track_data["FRAME_NUM"])

def get_track_lengths(json_out):
  track_lengths = {}
  for i in json_out.keys():
    if i != "META":
      track_lengths[i] = get_track_frame_length(json_out[i])

  return track_lengths

def largest_n_elements(in_list, n):
  sorted_list = sorted(in_list, reverse=True)
  return sorted_list[:n]

def largest_n_keys(dictionary, n):
  sorted_items = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)

  largest_keys = [item[0] for item in sorted_items[:n]]

  return largest_keys

def get_n_longest_tracks(json_out, n):
  longest_tracks = largest_n_keys(get_track_lengths(json_out), n)

  out = {}
  for i in longest_tracks:
    out[i] = json_out[str(i)]

  return out

def get_initial_frame(track):
  return track["FRAME_NUM"][0]

def get_final_frame(track):
  return track["FRAME_NUM"][-1]

def get_frame_range(track):
  return str(get_initial_frame(track)), str(get_final_frame(track))

def get_all_initial_frames(json_out):
  return [get_initial_frame(json_out[i]) for i in json_out.keys()]

def get_all_final_frames(json_out):
  return [get_final_frame(json_out[i]) for i in json_out.keys()]

def get_all_track_ranges(json_out):
  range_dict = {}
  for i in json_out.keys():
    range_dict[i] = get_frame_range(json_out[i])

  return range_dict

def get_all_track_info(json_out):
  out = {}

  out["TRACK_NUM"] = [i for i in json_out.keys()]
  out["i_FRAME"] = [get_initial_frame(json_out[i]) for i in json_out.keys()]
  out["f_FRAME"] = [get_final_frame(json_out[i]) for i in json_out.keys()]
  out["LENGTH"] = [get_track_frame_length(json_out[i]) for i in json_out.keys()]

  return pd.DataFrame(out)

def get_video(video_path):
  video = cv2.VideoCapture(video_path)

  if not video.isOpened():
    raise IOError("Error: Could not open video file.")

  return video

def get_frame(video, frame_number):
  video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)

  ret, frame = video.read()

  if not ret:
    raise IOError("Error: Could not read frame.")

  return frame

def load_track_file(file_path):
  with open(file_path, "r") as f:
    json_data = json.load(f)

  # Extract the title from the filename
  filename = os.path.basename(file_path)
  title = filename.split(".")[0].replace("OUT_", "")

  return json_data, title

#Intersection over union method for merging tracks
def calculate_iou(box1, box2):
    
    x1_inter = max(box1[0], box2[0])
    y1_inter = max(box1[1], box2[1])
    x2_inter = min(box1[2], box2[2])
    y2_inter = min(box1[3], box2[3])

    intersection_area = max(0, x2_inter - x1_inter + 1) * max(0, y2_inter - y1_inter + 1)

    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)
    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)
    union_area = box1_area + box2_area - intersection_area

    iou = intersection_area / union_area

    return iou

def get_ten_longest_track_data(json_out):
  longest_tracks = get_n_longest_tracks(json_out, 10)
  out = {}
  out["META"] = json_out["META"]

  for i in longest_tracks.keys():
    out[i] = longest_tracks[i]

  return out

@st.cache_data(experimental_allow_widgets=True)
def get_track_data(json_out, restrict_ten_longest=False):
  
  if restrict_ten_longest:
    json_out = get_ten_longest_track_data(json_out)

  track_df = get_track_teams(json_out)

  return track_df

def animate_dot_plotly(x_coordinates, y_coordinates, time_coordinates):
    # Create subplot
    fig = make_subplots(rows=1, cols=1, subplot_titles=['Animated Dot Plot'])

    # Scatter plot with initial point
    scatter = go.Scatter(x=[x_coordinates[0]], y=[y_coordinates[0]], mode='markers', marker=dict(color='blue', size=10))
    fig.add_trace(scatter)

    # Set layout
    fig.update_layout(
        xaxis=dict(range=[min(x_coordinates) - 1, max(x_coordinates) + 1]),
        yaxis=dict(range=[min(y_coordinates) - 1, max(y_coordinates) + 1]),
        showlegend=False
    )

    # Update function for animation
    def update(frame):
        scatter.x = [x_coordinates[frame]]
        scatter.y = [y_coordinates[frame]]

    # Create animation frames
    frames = [go.Frame(data=[go.Scatter(x=x_coordinates[:frame + 1], y=y_coordinates[:frame + 1], mode='markers',
                                         marker=dict(color='blue', size=10))],
                       traces=[0],
                       name=f'Frame {frame}')
              for frame in range(1, len(time_coordinates))]

    fig.frames = frames

    # Add animation settings
    animation_settings = dict(frame=dict(duration=1000, redraw=True), fromcurrent=True)
    fig.update_layout(updatemenus=[dict(type='buttons', showactive=False, buttons=[dict(label='Play',
                                            method='animate', args=[None, animation_settings])])])

    # Show the plot
    fig.show()

def view_tracks(video_filename, video_out, track_df):
  cap = cv2.VideoCapture(video_filename)
  ret, frame = cap.read()
  cap_out = cv2.VideoWriter(video_out, cv2.VideoWriter_fourcc(*'mp4v'), cap.get(cv2.CAP_PROP_FPS), (frame.shape[1], frame.shape[0]))

  frame_num = 0
  while ret:
    frame_num += 1
    frame_df = track_df[track_df["FRAME_NUM"] == frame_num]
    for index, row in frame_df.iterrows():
      point = (int(row["X"]), int(row["Y"]))
      cv2.circle(frame, point, 5, (0, 0, 255), -1)

      text = row["TEAM_ABBREV"] + ", " + str(row["TRACK_NUM"])
      font = cv2.FONT_HERSHEY_SIMPLEX
      font_scale = 0.8
      text_color = (255, 255, 255)  # BGR color (white in this example)
      text_thickness = 1

      # Calculate the position for the text
      text_position = (point[0] + 10, point[1] - 10)

      # Draw the text on the frame
      cv2.putText(frame, text, text_position, font, font_scale, text_color, text_thickness)
    cv2.imshow('frame', frame)
    cv2.waitKey(25)
    cap_out.write(frame)
    ret, frame = cap.read()

  cap.release()
  cap_out.release()
  cv2.destroyAllWindows()


